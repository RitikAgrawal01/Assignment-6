**Name:** Ritik Agrawal  
**Roll No:** DA25M026
# Imputation via Regression for Missing Data Analysis

## üìù Project Objective

This project investigates the impact of different missing data handling techniques on the performance of a credit risk classification model. The primary goal is to compare simple imputation, regression-based imputation (linear and non-linear), and listwise deletion to determine the most effective strategy for the UCI Credit Card Default dataset.

---

## üìä Dataset

The project uses the **UCI Credit Card Default Clients Dataset**. To simulate a real-world scenario, missing values (approx. 10%) were artificially introduced into the following key feature columns:
- `AGE`
- `BILL_AMT1`
- `LIMIT_BAL`

---

## üõ†Ô∏è Methodology

The core of the project involves a comparative experiment with four distinct strategies for handling the missing data:

1.  **Model A (Median Imputation):** A baseline approach where all missing values in the three columns are replaced by their respective medians.
2.  **Model B (Linear Regression Imputation):** Missing values in the `BILL_AMT1` column are predicted and filled using a Linear Regression model trained on other features.
3.  **Model C (KNN Regression Imputation):** A non-linear approach where a K-Nearest Neighbors regressor is used to impute the missing values in `BILL_AMT1`.
4.  **Model D (Listwise Deletion):** The simplest strategy, where all rows containing any missing values are completely removed from the dataset.

After applying each strategy, a **Logistic Regression classifier** was trained on the resulting dataset. The final performance of each strategy was evaluated based on the **F1-score** for predicting customer default.

---

## üèÜ Results & Conclusion

The experiment was run multiple times to ensure stable and reliable results. The final analysis revealed a clear winner:

| Model                       | Average F1-Score |
| --------------------------- | ---------------- |
| **D (Listwise Deletion)** | **0.3808** |
| A (Median Impute All)       | 0.3587         |
| C (KNN Reg Impute One)      | 0.3566         |
| B (Linear Reg Impute One)   | 0.3546         |

**Conclusion:** **Listwise Deletion (Model D) was the most effective strategy.**

The results indicate that for this dataset, the **quality of the data was more important than the quantity**. The imputed values generated by the other models, including the regression-based ones, likely introduced more statistical noise than valuable signal. The classifier performed better on a smaller, but cleaner and more truthful, dataset.

---

## üöÄ How to Run

To replicate this analysis, follow these steps:

1.  **Prerequisites:** Ensure you have Python 3 installed along with the following libraries:
    - `pandas`
    - `numpy`
    - `scikit-learn`
    - `matplotlib`
    - `seaborn`

    You can install them using pip:
    ```bash
    pip install pandas numpy scikit-learn matplotlib seaborn jupyterlab
    ```

2.  **Dataset:** Make sure the `UCI_Credit_Card.csv` file is in the same directory as the notebook.

3.  **Execution:** Open and run the `Assignment_6.ipynb` Jupyter Notebook from top to bottom. The notebook contains all the code for data processing, modeling, visualization, and the final analysis.